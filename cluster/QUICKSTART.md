# Quick Start Guide

## ğŸš€ Getting Started in 5 Minutes

This guide will get you running the EO Change Detection Pipeline quickly.

### Step 1: Validate Setup

```bash
cd cluster
python test_setup.py
```

This will check if all components are properly configured. Fix any issues reported.

### Step 2: Configure the Pipeline

Edit `pipeline/config/settings.py` to customize:

```python
# Basic configuration for testing
grid_ids = [463, 464]  # Start with just 2 grids
years = [2023, 2024]   # Test with recent years
btc_threshold = 0.2    # Change detection sensitivity
max_workers = 2        # Adjust based on your system
```

### Step 3: Build and Run

**Option A: Docker with Web Interface (Recommended)**

```bash
# Start the complete stack including the web-controlled pipeline
docker compose up -d

# Open the monitoring dashboard
open http://localhost:8080

# Click "Start Pipeline" in the web interface when ready
```

The pipeline will start in "wait mode" and display a monitoring dashboard at `http://localhost:8080`. You can:

- âœ… **Start** the pipeline by clicking the "Start Pipeline" button
- â¸ï¸ **Pause/Resume** pipeline execution
- â¹ï¸ **Stop** the pipeline at any time
- ğŸ”„ **Retry** failed tasks
- ğŸ“Š **Monitor** real-time progress and logs
- âš™ï¸ **Configure** years, grid IDs, and processing parameters

### ğŸ”§ Web Configuration Management

The monitoring dashboard now includes a **Pipeline Configuration** section where you can:

**ğŸ“… Set Years to Process:**

- Enter years separated by commas (e.g., `2020,2021,2022,2023,2024`)
- Valid range: 2015-2030

**ğŸ—ºï¸ Configure Grid IDs:**

- Specify which grid cells to process (e.g., `465,466,467`)
- Valid range: 1-1000

- predefined ranges

Ljubljana - 464,465,466,467,498,499,500,501,532,533,534,535,568,569,570,571

**âš¡ Adjust Processing Parameters:**

- Max Workers (1-32)
- Memory Limit (1-64 GB)
- BTC Threshold (0.0-1.0)
- Max Cloud Coverage (0-100%)

**ğŸ’¡ Configuration Features:**

- âœ… **Load Current Config** - View current settings
- âœ… **Apply Configuration** - Save changes
- âœ… **Reset to Defaults** - Restore default values
- ğŸ”’ **Locked During Execution** - Cannot change while pipeline runs

**Option B: Docker with Immediate Start**

```bash
# Build the container
./pipeline.sh build

# Start in local storage mode (good for testing)
./pipeline.sh start-local

# Monitor progress
./pipeline.sh monitor
# Open http://localhost:8080 in your browser
```

**Option C: Local Development**

```bash
# Install dependencies
pip install -r requirements_pipeline.txt
pip install -r requirements.txt

# Set environment
export PYTHONPATH=/Users/gasper/Documents/ViCos/eo_cd_slo/cluster
export DATA_DIR=/Users/gasper/Documents/ViCos/eo_cd_slo/cluster/data
export PIPELINE_MODE=local_only

# Run the pipeline
python -m pipeline.controller
```

### Step 4: Monitor Progress

**Web Dashboard**: Visit `http://localhost:8080`

- See real-time progress
- Monitor failed tasks
- View system resources

**Command Line**:

```bash
# Check status
./pipeline.sh status

# View logs
./pipeline.sh logs -f

# Retry failed tasks
./pipeline.sh retry
```

### Step 5: Access Results

**Local Mode Results**:

```
data/
â”œâ”€â”€ images/2023/sentinel2_grid_463_2023_08.tiff
â”œâ”€â”€ images/2024/sentinel2_grid_463_2024_08.tiff
â”œâ”€â”€ masks/2024/change_mask_grid_463_2024.png
â””â”€â”€ checkpoints/download_2023.json
```

**Generated Files**:

- **Images**: Original Sentinel-2 GeoTIFF files
- **Masks**: PNG change detection masks (white = change, black = no change)
- **Checkpoints**: JSON files for resuming interrupted runs
- **Metadata**: JSON files with processing information

## ğŸ¯ Processing Flow

1. **Download** (Year 2023): Downloads Sentinel-2 images for all grid cells
2. **Download** (Year 2024): Downloads Sentinel-2 images for all grid cells
3. **Insert** (Year 2023): Stores/processes 2023 images
4. **Insert** (Year 2024): Stores/processes 2024 images
5. **BTC Processing** (2023â†’2024): Generates change masks comparing consecutive years

## ğŸ› ï¸ Common Commands

```bash
# Pipeline Control
./pipeline.sh build              # Build Docker image
./pipeline.sh start-local        # Start with local storage
./pipeline.sh start-database     # Start with database storage
./pipeline.sh stop               # Stop the pipeline
./pipeline.sh status             # Show current status

# Monitoring
./pipeline.sh monitor            # Open web dashboard
./pipeline.sh logs               # View logs
./pipeline.sh logs -f            # Follow logs in real-time

# Maintenance
./pipeline.sh retry              # Retry failed tasks
./pipeline.sh clean              # Remove all data (âš ï¸  destructive)
./pipeline.sh shell              # Access container shell

# One-time runs
./pipeline.sh run-once local_only     # Run once and exit
./pipeline.sh run-once database_only  # Run with database storage
```

## ğŸ”§ Troubleshooting

**Import Errors**:

```bash
# Make sure you're in the cluster directory
cd /Users/gasper/Documents/ViCos/eo_cd_slo/cluster

# Test the setup
python test_setup.py
```

**Permission Issues**:

```bash
# Fix script permissions
chmod +x pipeline.sh test_setup.py

# Check data directory permissions
ls -la data/
```

**Docker Issues**:

```bash
# Check Docker is running
docker ps

# Rebuild if needed
./pipeline.sh clean
./pipeline.sh build
```

**Out of Memory**:

```bash
# Reduce workers in settings.py
max_workers = 1
memory_limit_gb = 2

# Or set environment variable
export MAX_WORKERS=1
```

## ğŸ“Š Expected Output

For a successful run with 2 grids and 2 years, you should see:

```
Download Stage (2023): 2/2 tasks completed
Download Stage (2024): 2/2 tasks completed
Insert Stage (2023): 2/2 tasks completed
Insert Stage (2024): 2/2 tasks completed
BTC Stage (2024): 2/2 tasks completed

Total: 10/10 tasks completed (100%)
```

Generated files:

- 4 TIFF images (2 grids Ã— 2 years)
- 2 change masks (2 grids Ã— 1 year pair)
- Multiple checkpoint files
- Processing logs

## ğŸ What's Next?

1. **Scale Up**: Add more grid IDs and years in `settings.py`
2. **Database Mode**: Use `./pipeline.sh start-database` for production
3. **Customize**: Modify BTC threshold, processing parameters
4. **Monitor**: Use the web dashboard for large runs
5. **Integrate**: Use the APIs to integrate with other systems

## ğŸ’¡ Tips

- Start small (2-3 grids) to test the setup
- Use local mode for development, database mode for production
- The pipeline is resumable - you can stop and restart anytime
- Monitor disk space when processing many grids/years
- GPU processing is much faster for BTC stage if available

Happy processing! ğŸ›°ï¸
